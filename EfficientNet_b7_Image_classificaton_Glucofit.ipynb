{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup and Data Loading"
      ],
      "metadata": {
        "id": "1HnT4bBCiRWz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvNxd_3oiJzI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.cloud import storage\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "food_names = [\n",
        "    \"apple_pie\", \"baby_back_ribs\", \"baklava\", \"beef_carpaccio\", \"beef_tartare\", \"beet_salad\",\n",
        "    \"beignets\", \"bibimbap\", \"bread_pudding\", \"breakfast_burrito\", \"bruschetta\", \"caesar_salad\",\n",
        "    \"cannoli\", \"caprese_salad\", \"carrot_cake\", \"ceviche\", \"cheesecake\", \"cheese_plate\",\n",
        "    \"chicken_curry\", \"chicken_quesadilla\", \"chicken_wings\", \"chocolate_cake\", \"chocolate_mousse\",\n",
        "    \"churros\", \"clam_chowder\", \"club_sandwich\", \"crab_cakes\", \"creme_brulee\", \"croque_madame\",\n",
        "    \"cup_cakes\", \"deviled_eggs\", \"donuts\", \"dumplings\", \"edamame\", \"eggs_benedict\", \"escargots\",\n",
        "    \"falafel\", \"filet_mignon\", \"fish_and_chips\", \"foie_gras\", \"french_fries\", \"french_onion_soup\",\n",
        "    \"french_toast\", \"fried_calamari\", \"fried_rice\", \"frozen_yogurt\", \"garlic_bread\", \"gnocchi\",\n",
        "    \"greek_salad\", \"grilled_cheese_sandwich\", \"grilled_salmon\", \"guacamole\", \"gyoza\", \"hamburger\",\n",
        "    \"hot_and_sour_soup\", \"hot_dog\", \"huevos_rancheros\", \"hummus\", \"ice_cream\", \"lasagna\",\n",
        "    \"lobster_bisque\", \"lobster_roll_sandwich\", \"macaroni_and_cheese\", \"macarons\", \"miso_soup\",\n",
        "    \"mussels\", \"nachos\", \"omelette\", \"onion_rings\", \"oysters\", \"pad_thai\", \"paella\", \"pancakes\",\n",
        "    \"panna_cotta\", \"peking_duck\", \"pho\", \"pizza\", \"pork_chop\", \"poutine\", \"prime_rib\",\n",
        "    \"pulled_pork_sandwich\", \"ramen\", \"ravioli\", \"red_velvet_cake\", \"risotto\", \"samosa\", \"sashimi\",\n",
        "    \"scallops\", \"seaweed_salad\", \"shrimp_and_grits\", \"spaghetti_bolognese\", \"spaghetti_carbonara\",\n",
        "    \"spring_rolls\", \"steak\", \"strawberry_shortcake\", \"sushi\", \"tacos\", \"takoyaki\", \"tiramisu\",\n",
        "    \"tuna_tartare\", \"waffles\"\n",
        "]"
      ],
      "metadata": {
        "id": "3uggn8Sxinvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food_dirs = {food: os.path.join('data', food) for food in food_names}\n",
        "\n",
        "# Base directory for data\n",
        "base_dir = 'data'"
      ],
      "metadata": {
        "id": "-z1bvrV3isk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "\n",
        "# Iterate over each food category and gather image paths\n",
        "for food in food_names:\n",
        "    food_dir = os.path.join(base_dir, food)\n",
        "    if os.path.exists(food_dir):\n",
        "        for img_file in os.listdir(food_dir):\n",
        "            img_path = os.path.join(food_dir, img_file)\n",
        "            data.append((img_path, food))\n",
        "    else:\n",
        "        print(f\"{food}: Directory not found at {food_dir}\")\n",
        "\n",
        "# Convert the data into a DataFrame for easier handling (optional)\n",
        "df = pd.DataFrame(data, columns=['image_path', 'label'])"
      ],
      "metadata": {
        "id": "__vgjXAuivJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "UfG3MICnixFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Splitting (Train, Validation, Test)"
      ],
      "metadata": {
        "id": "asIZnUFUicKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into train (85%) and temp (15%)\n",
        "train_df, temp_df = train_test_split(df, train_size=0.85, random_state=1)\n",
        "\n",
        "# Further split temp into validation (7.5%) and test (7.5%)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=1)\n"
      ],
      "metadata": {
        "id": "qUo9Ff62iegI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation and ImageDataGenerator Setup\n"
      ],
      "metadata": {
        "id": "O2DccqrvifuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# ImageDataGenerator for validation and test data (no augmentation)\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input\n",
        ")"
      ],
      "metadata": {
        "id": "f6_bPAa_iiKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Flow from DataFrame for validation images\n",
        "val_images = test_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Flow from DataFrame for test images\n",
        "test_images = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "YcCw8ezli50Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction and Model Definition"
      ],
      "metadata": {
        "id": "zHAEgZn9i8KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extractor(inputs):\n",
        "    feature_extractor = EfficientNetB7(input_shape=(224, 224, 3), include_top=False, weights='imagenet')(inputs)\n",
        "    return feature_extractor"
      ],
      "metadata": {
        "id": "ztg7U-Lni7g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classifier(inputs):\n",
        "    x = GlobalAveragePooling2D()(inputs)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation=\"relu\")(x)\n",
        "    x = Dense(512, activation=\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(101, activation=\"softmax\", name=\"classification\")(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "05BkWGYajAAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_compile_model():\n",
        "    inputs = Input(shape=(224, 224, 3))\n",
        "    efficientnet_feature_extractor = feature_extractor(inputs)\n",
        "    classification_output = classifier(efficientnet_feature_extractor)\n",
        "    model = Model(inputs=inputs, outputs=classification_output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "IUJtVJD_jBnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_compile_model()"
      ],
      "metadata": {
        "id": "7kZFJWnWjD5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "id": "6W9xyOgmjF65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Model Training"
      ],
      "metadata": {
        "id": "PfXciReUjHJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_images,\n",
        "    validation_data=val_images,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('EfficientNetB7_Model_food_classifier_model.h5')"
      ],
      "metadata": {
        "id": "hXsk-4kMjJgd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}